\section{Introduction}
\label{sec:intro} 

% - success of cloud computing.
% - ever-growing demand of computing resources (CR) -> production of CR.
% - economy of scale -> CR production is concentrated in mega datacenters.
% - mega DCs -> critical needs in electricity and cooling.
% - mega DCs in region with abundant and cheap electricity supply
% - mega DCs in region with free cooling. 
The success of Cloud Computing has driven the advent of Utility Computing (UC): 
to satisfy the the ever-growing demand for computing resources, cloud providers 
have build large infrastructures. To realize economy of scale, the production
of computing resources is concentrated in mega data centers (DCs) of 
ever-increasing size, where the number of physical resources that one DC can 
host is limited by the capacity of its energy supply and its cooling system. 
Hence, to meet these critical needs in terms of energy supply and cooling, the 
current trend is toward building DCs in regions with abundant and affordable 
electricity supplies or in regions close to the polar circle to leverage free 
cooling techniques. 


% - ever-increasing DCs size 
%   -> more concentration of production (general) 
%     -> problems:
%        * fault-tolerance (disasters).
% - alternative: deconcentration of computing resources.
% - federation of several clouds is a first is a solution for:
%      - fault tolerance.
%      - energy requirements.
Moreover, this ever-increasing DCs size is a problem as it accentuates the 
concentration of the production of computing resources in a same geographical
area, thus leading to fault tolerance issues: when a disaster occurs 
connectivity to computing resources cannot be guaranteed. As an alternative to 
this mono-site concentration of computing resources, federations of clouds 
propose to extend resources available on one Cloud with those of another one. 
One positive effect of federation of clouds is that it enables the 
decentralization of computing resources, thus solving the problems of 
connectivity in case of disasters, and dividing the electrical and cooling 
effort on several geographical sites.

% - mega DCs or federation of clouds -> data/apps far from users.
%   -> network overhead
% - IEEE report: network traffic has been doubling every years
% - example: CDNs decentralize the hosting of static resources.
However, all these DCs are still located in specific place present, in addition 
to jurisdiction concerns, the drawback of hosting computing resources far from 
end users, which leads to some useless network overheads that prevent the 
adoption of cloud computing by several kind of applications such as mobile 
computing or big data ones. A recent IEEE report \cite{ieeenetreport:2012}
shows that network traffic continues to double roughly every year. Consequently,
a model bringing computing resources closer to the end-users would minimize the 
energy impact and save bandwidth. An example of such model is Content Delivery 
Networks (CDNs) in web hosting: static resources like images and web scripts are
duplicated on servers located all over the world, enabling their distribution to
end users with low latency and high bandwidth by delivering from the closest 
server.
%This enables large websites to 
%dedicate DCs to high value computing like dynamic content generation.

% - apply the CDN model to the cloud.
% - We propose: instead of concentrating production of computing resources:
%    * leverage the concept of Micro/nano DC geographically spread.
% - Operate these micro DCs with a cloud OS: instead of several Clouds OS that
%   only use remote clouds, we propose a single Cloud OS that operate all of 
%   them in a distributed manner.
% - Classical models (centralized, federations) -> not good (SPOF, does not 
%  operate efficiently).
In keeping with the decentralization of resource delivering as allowed by models
like CDNs, we propose to study a model where the production of computing 
resources is decentralized: leveraging the concept of geographically spread 
micro/nano DCs \cite{greenberg:2008} directly located in Internet service 
providers (ISPs) points of presence \cite{lebre:beyond2013}, thereby benefiting 
from high connectivity (low latency and high bandwidth) with end users, there 
are several models that can be used to operate such an infrastructure. The first 
way to operate these geographically spread micro DCs is to use classical models 
like federations of clouds (each micro DC will host one cloud) and the use of a
centralized broker (a central server will arrange resource allocation by picking
on each cloud). These models cannot be considered as adequate: a central broker 
would expose the infrastructure to problems like scalability and single point of
failure (SPOF), and federation of clouds does not go far enough to operate a 
network of micro DCs as it would use rather than operate other clouds. The 
second way to operate such infrastructure is to design and build a Cloud 
Operating System (Cloud OS) that will operate all the geographically spread 
micro DCs in a fully distributed manner, thus preventing from SPOFs problems.
% - Alors que les federations fonctionnent sur le plus petit denominateur commun,
%   le Cloud OS passe par un Adapter (API + outils) qui va étendre les capacités
%   des clouds. Cela permet d'aller plus loin que les fédérations classiques et
%   de créer des mecanismes distribués la où ils sont classiquement centralisés
%   (noeuds de services).
While working with a federation of heterogeneous clouds means working on the 
least common denominator APIs, a Cloud OS will define and leverage its own 
software interface, thus extending capacities of a Cloud with its API and a set 
of tools. This allows to go beyond classical federations of Clouds and to 
implement, in a fully distributed manner, mechanisms that are traditionally 
centralized (service nodes).


% - Hierarchical structure -> maintenance cost and high complexity.
% - We want a flat structure and a single image system that will be distributed.
% - Geographicaly spread DCs -> need to take into account locality properties.
% - locality properties -> high overall reactivity.
Working in a fully distributed context implies that collaborations between 
instances of the system have to be structured whether in flat way or in a 
hierarchical one. As hierarchical structures lead to additional maintenance 
costs and an increase of the architectural complexity, it could not be a 
satisfactory solution. Moreover, mapping a tree architecture on top of a network
backbone is still not meaningfull.To operate massively distributed clouds build 
on top of close to end users micro DCs, we think that a single image system 
composed of several agents that will be distributed following a flat 
architecture is a good candidate. Furthermore, we deeply think that to 
efficiently operate such infrastructure, a Cloud OS needs to takes into account 
several measurements (latency, bandwidth, ...) aggregated as locality 
properties: it would efficiently organize collaborations between its computing 
resources, thus improving its overall reactivity. 

% - We propose: a Cloud OS that takes into account locality properties.
% - This system will be build on top of distributed mechanisms such as DHT and
%   advanced distributed models (p2p).
% - LUC-OS: many micro DCs operated by a single system.
% - The LUC-OS will be very interesting for ISPs: 
%     backbone -> complete UC resources
Hence we propose the Locality based Utility Computing Operating System (LUC-OS),
an advanced Cloud OS that will operate a massively distributed cloud by 
leveraging locality properties and a peer to peer architecture to efficiently 
work in a fully distributed manner. To address scalability and fault tolerance 
concerns, the LUC-OS will be build on top of advanced distributed mechanisms 
like overlay networks, distributed hashtables and actor model. The LUC-OS will 
enable the unification of many UC resources distributed on distinct sites, to be
operated through a single system. It would enable ISPs and other institutions in
charge of operating a network backbone to build an extreme-scale LUC 
infrastructure with a limited additional cost. Instead of redeploying a complete
installation, they will be able to leverage IT resources and specific devices 
such as computer room air conditioning units, inverters or redundant power 
supply.

% - Developing from scratch: herculean work.
% - We should maximize the reuse of existing tools/concepts.
% - To do so: 1) draw architectural summary; 2) identify challenges for the
%   LUC-OS 3) instantiate it over OpenStack.
As developing from scratch a Cloud OS is an herculean work, we think that the 
LUC-OS should leverage tools and concepts that existing systems use, even if 
it means modifications to some mechanisms to work in a fully distributed manner.
The design and the development of such a cloud OS is definitely a challenge: to 
address it, we propose to build on existing solutions. First, we propose 
to revisit the reference architecture of IaaS management systems (aka. cloudkit 
such as OpenStack, Nimbus, Eucalyptus, ...), in order to deliver a software 
architecture that can fit the requirements imposed by such a LUC system. The 
second step will consist in instantiating the established architecture on one of
the available system. We chose to perform such an instantiation on top of 
OpenStack. 

The remainder of this article is structured as follows. Section 2 discusses a 
reference architecture for clouds proposed by \cite{moreno2012iaas} by 
identifying challenges that need to be solved for building massively distributed 
clouds over geographically spread micro DCs. Section 3 gives an overview of the 
LUC OS design proposal that meet requirements from Section 2. In Section 4, 
methodology to build the LUC-OS over OpenStack is detailed. Finally, we 
discuss perspectives and conclude this article in Section 5.