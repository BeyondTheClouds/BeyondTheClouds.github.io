\subsection{Implementation of DVMS}

A prototype of DVMS leveraging the \emph{peer actor} abstraction has been 
developed. In addition we built two versions of the network overlay actor: one 
working with Chord, and one working with the Vivaldi based overlay. This mean 
that now DVMS is network overlay agnostic to, and thus can be used with either
of the network overlay without requiring any modification in it's source code.

The implementation is based on modern programming language and framework such as 
\emph{Scala} and \emph{Akka framework}. Scala is a language that mixes object
oriented programming with functional programming, it's compiler produces 
\emph{Java bytecode} which can be run in any JVM environment. Combining Scala 
with Akka enabled us to take advantage of advanced techniques for concurrent 
programming such as \emph{future/promise} and \emph{actor model}, and to benefit
from Java ease of deployment.



\subsection{Grid'5000 experiments}

\JP{Complete this section with more experimentation results.}

\subsubsection{Objectives}
The prototype has been tested with a various number of experiments conducted on
the Grid'5000 testbed. The main objective of the experiments was to estimate
impact of locality on the performance of a distributed scheduling algorithm. 
A significant portion of the reconfiguration time is spent in live migration of
virtual machines, which depends of network parameters such as latency and
bandwidth. One way to improve performance of distributed scheduling algorithm is
is to promote collaboration between close ressources, which can be reach by 
maximising this ratio:

\[
	\frac{number\ of\ intrasite\ migrations}{number\ of\ migrations}
\]

\subsubsection{Experimental protocol}
For each experiment, we booked 40 compute servers spread on 4 geographical sites
and 1 service server. The compute servers were used to run virtual machines and
DVMS while the service node is used to stress several parameters of 
virtual machines.

Each compute node will host a number of virtual machines proportional to the 
number of CPU cores it has. In our case:

\[
	number\ of\ virtual\ machines\ =\ 1.3\ \times\ number\ of\ cores
\]

\subsubsection{Results}

The impact of locality on DVMS is significant: using a Vivaldi based network
overlay leads to an average number of 83\% of intrasite migrations while using 
a Chord based DVMS leads a ratio of 50\% of intrasite migrations, as depicted
in the following table:


\begin{tabular}{|c|c|c|}
  
  % <HEADER>
  \hline
  network overlay & \multicolumn{1}{|p{3cm}|}{\centering average number of intrasite migrations}  & \multicolumn{1}{|p{3cm}|}{ \centering average number of migrations}  \\
  % </HEADER>

  % <ROW 1> => Vivaldi data
  \hline
  Vivaldi & 83 & 100 \\
  % </ROW 1>

  % <ROW 2> => Chord data
  \hline
  Chord & 40 & 80 \\
  % </ROW 2>

  \hline
\end{tabular}

